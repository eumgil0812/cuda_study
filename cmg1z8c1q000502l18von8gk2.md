---
title: "I/O Devices"
datePublished: Sat Sep 27 2025 07:56:09 GMT+0000 (Coordinated Universal Time)
cuid: cmg1z8c1q000502l18von8gk2
slug: io-devices
tags: io-devices

---

# Operating Systems and I/O Devices

Interrupts, DMA, and Driver Architecture

How an operating system controls I/O devices is far more than simply ‚Äúreading and writing data.‚Äù It involves **asymmetry between CPU and device speeds, efficiency trade-offs, and abstraction in OS design**. This post, based on *Operating Systems: Three Easy Pieces (OSTEP)*, summarizes the core concepts of I/O device management.

---

## 1\. Polling vs. Interrupts: CPU Utilization Perspective

### Polling (Programmed Polling)

* The CPU repeatedly checks a device status register.
    
* Simple to implement, but if the device is slow, CPU cycles are heavily wasted.
    

### Interrupt-driven I/O

* When the device finishes, it raises an interrupt that forces the CPU to react immediately.
    
* The OS puts the requesting process to **sleep ‚Üí context switch ‚Üí run other tasks**.
    
* Once I/O completes, the ISR (Interrupt Service Routine) executes and wakes the waiting process.
    

üëâ **Advantage**: Enables **overlap of CPU and I/O operations**, maximizing system utilization.  
üëâ **Disadvantage**: Interrupt handling itself involves context switching and ISR overhead.

---

## 2\. The Paradox of Interrupts: Not Always Optimal

While interrupts are generally seen as superior to polling, reality is more nuanced.

* **High-speed devices**: If operations finish almost instantly, polling can be more efficient.
    
    * (One or two polls suffice; no need for costly interrupt context switching.)
        
* **Interrupt Floods in Networking**: At high packet rates, the CPU may handle only interrupts and starve user-level processes, leading to **livelock**.
    
* **Alternatives**:
    
    * **Hybrid approach**: Poll for a short while, then switch to interrupts if not done.
        
    * **Interrupt Coalescing**: Aggregate multiple events into a single interrupt (trade-off between efficiency and latency).
        

‚û°Ô∏è Thus, OSes must **strategically combine polling, interrupts, or hybrids depending on device speed and workload patterns**.

---

## 3\. PIO vs. DMA: Offloading Data Movement

### Programmed I/O (PIO)

* The CPU explicitly copies data **word by word** from memory to the device.
    
* For large transfers, CPU time is wasted performing trivial copy operations.
    

### Direct Memory Access (DMA)

* A dedicated DMA engine transfers data between memory and device **without CPU intervention**.
    
* The OS specifies the buffer address, size, and target device, then continues with other work.
    
* Upon completion, the DMA controller raises an interrupt to notify the OS.
    

üëâ **Result**: CPU is freed from copy operations ‚Üí better concurrency and efficiency.  
üëâ **Trade-off**: DMA setup cost + potential bus contention.

---

## 4\. Device Access Methods: Port I/O vs. Memory-Mapped I/O

1. **Port I/O (Dedicated Instructions)**
    
    * x86 uses `in` and `out` instructions to access specific ports.
        
    * Privileged: only OS kernel can issue them.
        
2. **Memory-Mapped I/O (MMIO)**
    
    * Device registers are mapped into memory address space.
        
    * CPU accesses them with standard `load/store` instructions.
        

‚û°Ô∏è Port I/O is more traditional and strict, while MMIO is simpler and more flexible. Modern systems often use both.

---

## 5\. Device Drivers: Abstraction and Its Limits

The OS cannot know the peculiarities of every device. The solution is **abstraction**.

* **Generic Block Layer**: Handles file system read/write requests in abstract block units.
    
* **Device Driver**: Implements the hardware-specific protocol (SCSI, ATA, USB, etc.).
    
* **Application & FS**: Use the same API (`open`, `read`, `write`, `close`) regardless of device type.
    

### Pros

* Keeps most OS code **device-neutral**.
    

### Cons

* Device-specific advanced features may be lost during abstraction.
    
    * Example: Linux simplifies rich SCSI error reporting into a generic `EIO`.
        

### Reality

* Over **70% of Linux kernel code is device drivers**.
    
* Many are vendor-supplied, often lower quality, making drivers a primary source of kernel bugs.
    

---

## 6\. Case Study: xv6 IDE Disk Driver

The xv6 teaching OS provides a minimal but illustrative IDE driver.

* **Registers**:
    
    * `0x1F0`: Data port
        
    * `0x1F7`: Status/command (BUSY, READY, ERROR bits)
        
* **Protocol**:
    
    1. Poll `Status Register` until READY and not BUSY.
        
    2. Write sector count, LBA, and drive number.
        
    3. Issue `READ` or `WRITE` command.
        
    4. For write: send data via data port.
        
    5. For read: handle interrupt and transfer data.
        
    6. On error: check `Error Register`.
        
* **Driver functions**:
    
    * `ide_rw()`: Manages request queue.
        
    * `ide_start_request()`: Sets registers and initiates command.
        
    * `ide_wait_ready()`: Spins until device is ready.
        
    * `ide_intr()`: Handles interrupt, transfers data, wakes process, starts next request.
        

‚û°Ô∏è Even in a teaching OS, we see the same structural patterns: queueing, synchronization, and ISR-based handling‚Äîfundamental to all modern drivers.

---

## 7\. Historical Context

* **Interrupts**: Already present in UNIVAC systems of the 1950s.
    
* **DMA**: Introduced in mid-1950s systems like IBM SAGE and DYSEAC.
    

These were not revolutionary leaps, but **natural responses to the CPU‚ÄìI/O performance gap**.

---

## 8\. Conclusion

Key takeaways from OS‚ÄìI/O device interaction:

1. **Polling vs. Interrupts**: Choice depends on device speed, workload, and overhead trade-offs.
    
2. **DMA**: Offloads data transfer, freeing the CPU.
    
3. **Access methods**: Both Port I/O and MMIO remain in use.
    
4. **Drivers as abstraction**: Enable device neutrality but limit advanced features and increase bug-prone code.
    

Ultimately, I/O management is not just about efficiency‚Äîit is about **balancing resources, abstracting complexity, and dealing with hardware diversity**.

---

üìå In a follow-up, I‚Äôll dive into **I/O scheduling and file system optimizations (caching, journaling, log-structured design)** to connect device-level management with higher-level OS performance.

---