---
title: "(11) Physical Memory Manager (PMM)"
datePublished: Wed Oct 22 2025 13:11:51 GMT+0000 (Coordinated Universal Time)
cuid: cmh20imf9000402jm22wu17e8
slug: 11-physical-memory-manager-pmm
tags: pmm

---

When the OS boots, we first obtain a **memory map** that tells us which physical RAM addresses are usable.

Now we’ll implement the **PMM** that actually manages that memory

## 1) What is PMM?

**PMM (Physical Memory Manager)** is the kernel’s most basic manager for **physical** memory.  
In plain terms, it’s the system that tracks:

> “Which parts of RAM are **in use**, and which parts are **free**?”

Based on the UEFI **memory map**, the PMM divides RAM into **pages** (typically **4 KB**) and keeps a **bitmap** that marks each page as **used** or **free**.

### Responsibilities

| Function | Description |
| --- | --- |
| **Page tracking** | Split physical RAM into pages and record each page’s state as a single bit. |
| **Allocation (**`alloc`) | Find a free page and hand its physical address to the kernel. |
| **Freeing (**`free`) | Mark a page as free again when it’s no longer needed. |
| **Reservation (**`reserve`) | Pre-mark pages that must not be reused (kernel image, framebuffer, bootloader buffers, etc.). |

## 2) How the PMM works (Bitmap model)

The PMM manages RAM in **page** units (usually 4 KB).  
To mark whether each page is **used** or **free**, it uses a simple **bitmap** array.

### Bitmap structure

Each **bit** represents **one 4 KB page**:

| Bit | Meaning |
| --- | --- |
| `0` | Free |
| `1` | Used / Reserved |

Example: with **1 MB** of RAM

* `1 MB / 4 KB = 256 pages`
    
* 1 bit per page ⇒ **256 bits = 32 bytes** of bitmap is enough.  
    This is why a bitmap is extremely space-efficient for managing large RAM.
    

### Core algorithm

| Step | Action | Notes |
| --- | --- | --- |
| **1\. Initialization** | Select only `Type = 7 (EfiConventionalMemory)` from the memory map. | Only regions the kernel may use become the PMM’s managed space. |
| **2\. Create the bitmap** | Size it for the total page count and zero-initialize it. | `0` means “all free” to start with. |
| **3\. Mark reservations** | Mark known in-use ranges as `1`. | Kernel image, framebuffer, etc. via `mark_range_used()`. |
| **4\. Allocate** | Find the first `0` bit, flip to `1`, return its physical address. | `pmm_alloc_page()` |
| **5\. Free** | Flip the bit back to `0`. | `pmm_free_page()` |

bit map

```c
[0 0 1 0 0 1 0 1]
```

| 페이지 | 상태 |
| --- | --- |
| 0 | free |
| 1 | free |
| 2 | used |
| 3 | free |
| 4 | free |
| 5 | used |
| 6 | free |
| 7 | used |

→ Pages 2, 5, and 7 are already allocated.  
When a new page is requested, the `alloc()` function searches for the first index whose bit is `0` (for example, index `0`), flips it to `1`, and returns the corresponding physical address.

## PMM.C

### pmm\_init

```c
void pmm_init(BootInfo* bi, uint64_t min_phys) {
    // 1) Select the largest "Conventional" (Type=7) memory block above min_phys
    uint8_t* p = (uint8_t*)bi->MemoryMap;
    uint64_t best_start = 0, best_len = 0;

    for (uint64_t off = 0; off < bi->MemoryMapSize; off += bi->DescriptorSize) {
        EFI_MEMORY_DESCRIPTOR* d = (EFI_MEMORY_DESCRIPTOR*)(p + off);
        if (d->Type != 7) continue; // Only EfiConventionalMemory regions are usable
        uint64_t start = (uint64_t)d->PhysicalStart;
        uint64_t end   = start + ((uint64_t)d->NumberOfPages << 12);
        if (end <= min_phys) continue;
        if (start < min_phys) start = min_phys;  // Skip below min_phys
        uint64_t len = end - start;
        if (len > best_len) { best_len = len; best_start = start; }
    }

    // 2) Initialize PMM state
    PMM.base   = PAGE_ALIGN_UP(best_start);
    PMM.length = PAGE_ALIGN_DOWN(best_start + best_len) - PMM.base;
    PMM.total_pages = PMM.length / PAGE_SIZE;
    PMM.used_pages  = 0;

    // 3) Allocate bitmap memory
    //    The bitmap itself is stored in a static buffer for demo purposes.
    //    In a real kernel, this would come from kmalloc or a dedicated heap area.
    static uint8_t bitmap_storage[1 << 20]; // 1MB → 8,388,608 bits = covers ~32GB of RAM
    PMM.bitmap = bitmap_storage;
    PMM.bitmap_bytes = (PMM.total_pages + 7) / 8;
    if (PMM.bitmap_bytes > sizeof(bitmap_storage)) {
        // If too large, clamp it to prevent overflow (demo safety measure).
        uint64_t max_pages = (sizeof(bitmap_storage) * 8ULL);
        PMM.total_pages = (max_pages < PMM.total_pages) ? max_pages : PMM.total_pages;
        PMM.length = PMM.total_pages * PAGE_SIZE;
        PMM.bitmap_bytes = (PMM.total_pages + 7) / 8;
    }
    memset(PMM.bitmap, 0, PMM.bitmap_bytes);

    // 4) Mark reserved regions
    //    (a) Memory outside PMM range is ignored automatically
    //    (b) Known reserved resources are explicitly marked as used:
    //       - Kernel code/data (roughly 1MiB–current link end)
    //       - Framebuffer region
    //       - Bootloader’s memory map copy (optional, if known)
    //
    // The framebuffer base is assumed to be a physical address (as provided by GOP).
    // If it’s virtual, this reservation can be skipped.
    mark_range_used((uint64_t)(uintptr_t)bi->FrameBufferBase,
                    (uint64_t)bi->PixelsPerScanLine * bi->VerticalResolution * 4ULL);

    // Optionally reserve low memory (e.g., 0x100000–0x400000) used by kernel
    mark_range_used(0x00100000ULL, 0x00300000ULL);

    kprintf(bi, "[PMM] base=0x%llx, len=%llu MB, pages=%llu, bitmap=%llu bytes\n",
            (unsigned long long)PMM.base,
            (unsigned long long)(PMM.length >> 20),
            (unsigned long long)PMM.total_pages,
            (unsigned long long)PMM.bitmap_bytes);
}
```

Step-by-step Explanation

| Step | Description |
| --- | --- |
| **1\. Find the largest usable block** | Scans the UEFI memory map to locate the biggest **EfiConventionalMemory** region above `min_phys`. This becomes the region managed by PMM. |
| **2\. Initialize PMM state** | Aligns the start/end to page boundaries and calculates total/used pages. |
| **3\. Allocate the bitmap** | Creates a 1 MB static array to track page usage. Each bit represents one 4 KB page (up to ~32 GB of coverage). |
| **4\. Reserve known regions** | Marks memory already in use (kernel, framebuffer, etc.) as "used" in the bitmap to prevent accidental reallocation. |
| **5\. Print summary** | Logs the base address, length, total pages, and bitmap size for debugging. |

### pmm\_alloc\_page

```c
void* pmm_alloc_page(void) {
    if (!PMM.bitmap || PMM.total_pages == 0) return NULL;

    // Simple linear scan
    for (uint64_t i = 0; i < PMM.total_pages; ++i) {
        if (!bitmap_test(i)) {                // Found a free page
            bitmap_set(i);                    // Mark it as used
            PMM.used_pages++;                 // Increment usage count
            return (void*)(uintptr_t)(PMM.base + i * PAGE_SIZE); // Return physical address
        }
    }
    return NULL; // No free pages available
}
```

Step-by-Step Explanation

| Step | Description |
| --- | --- |
| **1\. Validate state** | Checks that the bitmap is initialized (`PMM.bitmap`) and that there are pages to manage ([`PMM.total`](http://PMM.total)`_pages > 0`). |
| **2\. Scan the bitmap** | Iterates through all page entries, looking for the first free page (bit = 0). |
| **3\. Mark as used** | Sets the corresponding bit to 1 to mark the page as “used.” |
| **4\. Update counters** | Increments `PMM.used_pages` to keep track of the number of allocated pages. |
| **5\. Return the address** | Calculates the physical address as `PMM.base + i * PAGE_SIZE` and returns it. |
| **6\. Failure case** | If no free pages remain, returns `NULL`. |

### pmm\_free\_page

```c
void pmm_free_page(void* pa) {
    if (!pa) return;
    uint64_t phys = (uint64_t)(uintptr_t)pa;

    if (phys < PMM.base || phys >= PMM.base + PMM.length) return; // Outside managed range
    if ((phys - PMM.base) & (PAGE_SIZE - 1)) return;              // Not page-aligned

    uint64_t idx = (phys - PMM.base) / PAGE_SIZE;
    if (bitmap_test(idx)) {
        bitmap_clear(idx);
        if (PMM.used_pages) PMM.used_pages--;
    }
}
```

Step-by-Step Explanation

| Step | Description |
| --- | --- |
| **1\. Null check** | Returns immediately if the pointer `pa` is `NULL`. |
| **2\. Convert to physical address** | Casts the pointer to a 64-bit integer (`uint64_t`) for arithmetic. |
| **3\. Range validation** | Ensures the address is **within the managed PMM region** (`PMM.base` → `PMM.base + PMM.length`). If not, it’s ignored. |
| **4\. Alignment check** | Verifies that the address is **page-aligned**. If not aligned to 4 KB, it’s invalid and skipped. |
| **5\. Compute bitmap index** | Calculates which bit corresponds to this page: `(phys - PMM.base) / PAGE_SIZE`. |
| **6\. Free the page** | If the bit is set (used), clear it and decrement `PMM.used_pages`. |

## Result

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1761138374533/a04ebdd9-8dcd-4645-b56f-c29eacd8e149.png align="center")

```c
[PMM] base=0x1780000, len=35 MB, pages=9205, bitmap=1151 bytes
[PMM] total=9205 pages (35 MiB)
[PMM] used =0 pages (0 B)
```

---

### Interpretation

| **Item** | **Description** |
| --- | --- |
| **base = 0x1780000** | The starting physical address of the memory region managed by the PMM — in other words, the first usable RAM block for the kernel. |
| **len = 35 MB** | The total size of the contiguous memory area that the PMM manages (35 MB). |
| **pages = 9205** | The number of pages within that region (`35 MiB / 4 KiB = 9205`). |
| **bitmap = 1151 bytes** | The amount of memory required to track those 9205 pages — one bit per page (`9205 / 8 ≈ 1151 bytes`). |
| **total = 9205 pages (35 MiB)** | The total amount of memory currently under PMM management. |
| **used = 0 pages (0 B)** | Indicates that no pages have been reserved or allocated yet. |

---

## Summary

In other words, the kernel can control a **35 MiB block** of usable RAM starting at **0x00178000**,  
consisting of **9205 pages**, and **none of those pages have been used yet**.

This output confirms that the **PMM has been successfully initialized**.